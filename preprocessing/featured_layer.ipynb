{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import collections\n",
    "import logging\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurando nível de logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lendo arquivos de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet('../dataset/delivery/dlzd_olist_order_reviews_training.parquet.snappy')\n",
    "X_test = pd.read_parquet('../dataset/delivery/dlzd_olist_order_reviews_test.parquet.snappy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alterando rótulos para mais adequados ao modelo doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['review_tag'] = X_train['review_sentiment'].replace(\n",
    "    {\n",
    "        -1: 'negative',\n",
    "        0: 'neutral',\n",
    "        1: 'positive'\n",
    "    }\n",
    ")\n",
    "\n",
    "X_test['review_tag'] = X_test['review_sentiment'].replace(\n",
    "    {\n",
    "        -1: 'negative',\n",
    "        0: 'neutral',\n",
    "        1: 'positive'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando tag para armazenar marcar cada documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents = []\n",
    "\n",
    "for index, data in X_train.iterrows():\n",
    "    train_documents.append(TaggedDocument(data['review_comment_title_and_message'].tolist(), [data['review_tag']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_documents = []\n",
    "\n",
    "for index, data in X_test.iterrows():\n",
    "    test_documents.append(TaggedDocument(data['review_comment_title_and_message'].tolist(), [data['review_tag']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo modelo Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 19:50:42,985 : INFO : using concatenative 6000-dimensional layer1\n",
      "2024-09-23 19:50:42,991 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/c,d400,n5,w7,mc3,s1e-05,t8>', 'datetime': '2024-09-23T19:50:42.991391', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(\n",
    "    vector_size=400, # tamanho do vetor de embedding\n",
    "    min_count=3, # quantidade mínima de repetições palavras para entrarem no treinamento \n",
    "    sample=10**-5, # frequência teórica para ponderar palavras muito frequêntes\n",
    "    window=7, # número máximo de palavras utilizadas para prever a palavra alvo\n",
    "    shrink_windows=True, # abilitando troca dinâmica da janela de 1 a 7 palavras\n",
    "    hs=0, # utilizando amostragem negativa para acelarar o treinamento\n",
    "    negative=5, # determina que 20 palavras aleatórias serão utilizadas para treinar a palavra predita\n",
    "    dm=1, # usando modelo PV-DM\n",
    "    dm_concat=1, # concatenando vetor de parágrafo com de palavras\n",
    "    dbow_words=1, # treinando também vetor de palavras word2vec\n",
    "    workers=8, # numero sde cores utilizados no paralelismo\n",
    "    seed=51, # fixando a aleatoriada para deixar o modelo reprodutível\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 19:50:44,263 : INFO : collecting all words and their counts\n",
      "2024-09-23 19:50:44,266 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2024-09-23 19:50:44,301 : INFO : PROGRESS: at example #10000, processed 79054 words (2414843 words/s), 6711 word types, 3 tags\n",
      "2024-09-23 19:50:44,320 : INFO : collected 8735 word types and 3 unique tags from a corpus of 16512 examples and 129470 words\n",
      "2024-09-23 19:50:44,321 : INFO : Creating a fresh vocabulary\n",
      "2024-09-23 19:50:44,335 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 2980 unique words (34.12% of original 8735, drops 5755)', 'datetime': '2024-09-23T19:50:44.335078', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-09-23 19:50:44,337 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 122544 word corpus (94.65% of original 129470, drops 6926)', 'datetime': '2024-09-23T19:50:44.337082', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-09-23 19:50:44,363 : INFO : deleting the raw counts dictionary of 8735 items\n",
      "2024-09-23 19:50:44,364 : INFO : sample=1e-05 downsamples 2403 most-common words\n",
      "2024-09-23 19:50:44,365 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 17314.65936939729 word corpus (14.1%% of prior 122544)', 'datetime': '2024-09-23T19:50:44.365080', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-09-23 19:50:44,395 : INFO : estimated required memory for 2980 words and 400 dimensions: 77783400 bytes\n",
      "2024-09-23 19:50:44,396 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(train_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 19:50:44,846 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 8 workers on 2981 vocabulary and 6000 features, using sg=0 hs=0 sample=1e-05 negative=5 window=7 shrink_windows=True', 'datetime': '2024-09-23T19:50:44.846575', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'train'}\n",
      "2024-09-23 19:50:45,402 : INFO : EPOCH 0: training on 129470 raw words (33797 effective words) took 0.5s, 64563 effective words/s\n",
      "2024-09-23 19:50:45,944 : INFO : EPOCH 1: training on 129470 raw words (33940 effective words) took 0.5s, 65173 effective words/s\n",
      "2024-09-23 19:50:46,487 : INFO : EPOCH 2: training on 129470 raw words (33702 effective words) took 0.5s, 64386 effective words/s\n",
      "2024-09-23 19:50:47,014 : INFO : EPOCH 3: training on 129470 raw words (33971 effective words) took 0.5s, 67308 effective words/s\n",
      "2024-09-23 19:50:47,597 : INFO : EPOCH 4: training on 129470 raw words (33915 effective words) took 0.6s, 60167 effective words/s\n",
      "2024-09-23 19:50:48,134 : INFO : EPOCH 5: training on 129470 raw words (33617 effective words) took 0.5s, 64898 effective words/s\n",
      "2024-09-23 19:50:48,667 : INFO : EPOCH 6: training on 129470 raw words (33797 effective words) took 0.5s, 65508 effective words/s\n",
      "2024-09-23 19:50:49,214 : INFO : EPOCH 7: training on 129470 raw words (34019 effective words) took 0.5s, 63852 effective words/s\n",
      "2024-09-23 19:50:49,729 : INFO : EPOCH 8: training on 129470 raw words (33650 effective words) took 0.5s, 68292 effective words/s\n",
      "2024-09-23 19:50:50,243 : INFO : EPOCH 9: training on 129470 raw words (33778 effective words) took 0.5s, 68328 effective words/s\n",
      "2024-09-23 19:50:50,777 : INFO : EPOCH 10: training on 129470 raw words (33757 effective words) took 0.5s, 65572 effective words/s\n",
      "2024-09-23 19:50:51,293 : INFO : EPOCH 11: training on 129470 raw words (33931 effective words) took 0.5s, 68693 effective words/s\n",
      "2024-09-23 19:50:51,801 : INFO : EPOCH 12: training on 129470 raw words (33779 effective words) took 0.5s, 69358 effective words/s\n",
      "2024-09-23 19:50:52,315 : INFO : EPOCH 13: training on 129470 raw words (33691 effective words) took 0.5s, 67021 effective words/s\n",
      "2024-09-23 19:50:52,838 : INFO : EPOCH 14: training on 129470 raw words (33857 effective words) took 0.5s, 67631 effective words/s\n",
      "2024-09-23 19:50:53,371 : INFO : EPOCH 15: training on 129470 raw words (33795 effective words) took 0.5s, 66549 effective words/s\n",
      "2024-09-23 19:50:53,877 : INFO : EPOCH 16: training on 129470 raw words (33866 effective words) took 0.5s, 68849 effective words/s\n",
      "2024-09-23 19:50:54,416 : INFO : EPOCH 17: training on 129470 raw words (34089 effective words) took 0.5s, 65892 effective words/s\n",
      "2024-09-23 19:50:54,948 : INFO : EPOCH 18: training on 129470 raw words (33843 effective words) took 0.5s, 66526 effective words/s\n",
      "2024-09-23 19:50:55,467 : INFO : EPOCH 19: training on 129470 raw words (33752 effective words) took 0.5s, 67202 effective words/s\n",
      "2024-09-23 19:50:55,975 : INFO : EPOCH 20: training on 129470 raw words (33945 effective words) took 0.5s, 69629 effective words/s\n",
      "2024-09-23 19:50:56,492 : INFO : EPOCH 21: training on 129470 raw words (33947 effective words) took 0.5s, 68422 effective words/s\n",
      "2024-09-23 19:50:57,042 : INFO : EPOCH 22: training on 129470 raw words (33731 effective words) took 0.5s, 63514 effective words/s\n",
      "2024-09-23 19:50:57,592 : INFO : EPOCH 23: training on 129470 raw words (33901 effective words) took 0.5s, 63927 effective words/s\n",
      "2024-09-23 19:50:58,118 : INFO : EPOCH 24: training on 129470 raw words (33764 effective words) took 0.5s, 66771 effective words/s\n",
      "2024-09-23 19:50:58,656 : INFO : EPOCH 25: training on 129470 raw words (33797 effective words) took 0.5s, 65253 effective words/s\n",
      "2024-09-23 19:50:59,254 : INFO : EPOCH 26: training on 129470 raw words (33774 effective words) took 0.6s, 58712 effective words/s\n",
      "2024-09-23 19:50:59,783 : INFO : EPOCH 27: training on 129470 raw words (33751 effective words) took 0.5s, 66218 effective words/s\n",
      "2024-09-23 19:51:00,302 : INFO : EPOCH 28: training on 129470 raw words (33920 effective words) took 0.5s, 67871 effective words/s\n",
      "2024-09-23 19:51:00,861 : INFO : EPOCH 29: training on 129470 raw words (33950 effective words) took 0.5s, 63488 effective words/s\n",
      "2024-09-23 19:51:01,385 : INFO : EPOCH 30: training on 129470 raw words (33977 effective words) took 0.5s, 66212 effective words/s\n",
      "2024-09-23 19:51:01,934 : INFO : EPOCH 31: training on 129470 raw words (33912 effective words) took 0.5s, 64804 effective words/s\n",
      "2024-09-23 19:51:02,485 : INFO : EPOCH 32: training on 129470 raw words (33963 effective words) took 0.5s, 62925 effective words/s\n",
      "2024-09-23 19:51:02,992 : INFO : EPOCH 33: training on 129470 raw words (33757 effective words) took 0.5s, 68415 effective words/s\n",
      "2024-09-23 19:51:03,504 : INFO : EPOCH 34: training on 129470 raw words (33663 effective words) took 0.5s, 67406 effective words/s\n",
      "2024-09-23 19:51:04,024 : INFO : EPOCH 35: training on 129470 raw words (33776 effective words) took 0.5s, 67579 effective words/s\n",
      "2024-09-23 19:51:04,568 : INFO : EPOCH 36: training on 129470 raw words (33728 effective words) took 0.5s, 64919 effective words/s\n",
      "2024-09-23 19:51:05,093 : INFO : EPOCH 37: training on 129470 raw words (33868 effective words) took 0.5s, 66433 effective words/s\n",
      "2024-09-23 19:51:05,625 : INFO : EPOCH 38: training on 129470 raw words (33756 effective words) took 0.5s, 66023 effective words/s\n",
      "2024-09-23 19:51:06,157 : INFO : EPOCH 39: training on 129470 raw words (33936 effective words) took 0.5s, 66260 effective words/s\n",
      "2024-09-23 19:51:06,708 : INFO : EPOCH 40: training on 129470 raw words (33902 effective words) took 0.5s, 63773 effective words/s\n",
      "2024-09-23 19:51:07,222 : INFO : EPOCH 41: training on 129470 raw words (33858 effective words) took 0.5s, 68514 effective words/s\n",
      "2024-09-23 19:51:07,724 : INFO : EPOCH 42: training on 129470 raw words (33772 effective words) took 0.5s, 70489 effective words/s\n",
      "2024-09-23 19:51:08,227 : INFO : EPOCH 43: training on 129470 raw words (33723 effective words) took 0.5s, 69372 effective words/s\n",
      "2024-09-23 19:51:08,728 : INFO : EPOCH 44: training on 129470 raw words (33753 effective words) took 0.5s, 70201 effective words/s\n",
      "2024-09-23 19:51:09,234 : INFO : EPOCH 45: training on 129470 raw words (33890 effective words) took 0.5s, 69909 effective words/s\n",
      "2024-09-23 19:51:09,730 : INFO : EPOCH 46: training on 129470 raw words (33808 effective words) took 0.5s, 70976 effective words/s\n",
      "2024-09-23 19:51:10,228 : INFO : EPOCH 47: training on 129470 raw words (33925 effective words) took 0.5s, 70597 effective words/s\n",
      "2024-09-23 19:51:10,728 : INFO : EPOCH 48: training on 129470 raw words (33865 effective words) took 0.5s, 70348 effective words/s\n",
      "2024-09-23 19:51:11,232 : INFO : EPOCH 49: training on 129470 raw words (33713 effective words) took 0.5s, 70323 effective words/s\n",
      "2024-09-23 19:51:11,735 : INFO : EPOCH 50: training on 129470 raw words (33880 effective words) took 0.5s, 68716 effective words/s\n",
      "2024-09-23 19:51:12,236 : INFO : EPOCH 51: training on 129470 raw words (33739 effective words) took 0.5s, 69940 effective words/s\n",
      "2024-09-23 19:51:12,744 : INFO : EPOCH 52: training on 129470 raw words (33734 effective words) took 0.5s, 69273 effective words/s\n",
      "2024-09-23 19:51:13,249 : INFO : EPOCH 53: training on 129470 raw words (33859 effective words) took 0.5s, 69685 effective words/s\n",
      "2024-09-23 19:51:13,751 : INFO : EPOCH 54: training on 129470 raw words (33689 effective words) took 0.5s, 69926 effective words/s\n",
      "2024-09-23 19:51:14,256 : INFO : EPOCH 55: training on 129470 raw words (33851 effective words) took 0.5s, 68704 effective words/s\n",
      "2024-09-23 19:51:14,755 : INFO : EPOCH 56: training on 129470 raw words (33726 effective words) took 0.5s, 70680 effective words/s\n",
      "2024-09-23 19:51:15,244 : INFO : EPOCH 57: training on 129470 raw words (33777 effective words) took 0.5s, 72088 effective words/s\n",
      "2024-09-23 19:51:15,734 : INFO : EPOCH 58: training on 129470 raw words (33898 effective words) took 0.5s, 71847 effective words/s\n",
      "2024-09-23 19:51:16,277 : INFO : EPOCH 59: training on 129470 raw words (33891 effective words) took 0.5s, 64838 effective words/s\n",
      "2024-09-23 19:51:16,770 : INFO : EPOCH 60: training on 129470 raw words (33784 effective words) took 0.5s, 71669 effective words/s\n",
      "2024-09-23 19:51:17,259 : INFO : EPOCH 61: training on 129470 raw words (33781 effective words) took 0.5s, 72289 effective words/s\n",
      "2024-09-23 19:51:17,756 : INFO : EPOCH 62: training on 129470 raw words (34073 effective words) took 0.5s, 71742 effective words/s\n",
      "2024-09-23 19:51:18,313 : INFO : EPOCH 63: training on 129470 raw words (34021 effective words) took 0.5s, 63319 effective words/s\n",
      "2024-09-23 19:51:18,835 : INFO : EPOCH 64: training on 129470 raw words (33692 effective words) took 0.5s, 66839 effective words/s\n",
      "2024-09-23 19:51:19,328 : INFO : EPOCH 65: training on 129470 raw words (33793 effective words) took 0.5s, 71241 effective words/s\n",
      "2024-09-23 19:51:19,958 : INFO : EPOCH 66: training on 129470 raw words (33824 effective words) took 0.6s, 55637 effective words/s\n",
      "2024-09-23 19:51:20,451 : INFO : EPOCH 67: training on 129470 raw words (33790 effective words) took 0.5s, 71850 effective words/s\n",
      "2024-09-23 19:51:20,976 : INFO : EPOCH 68: training on 129470 raw words (33691 effective words) took 0.5s, 66875 effective words/s\n",
      "2024-09-23 19:51:21,470 : INFO : EPOCH 69: training on 129470 raw words (33805 effective words) took 0.5s, 71355 effective words/s\n",
      "2024-09-23 19:51:21,471 : INFO : Doc2Vec lifecycle event {'msg': 'training on 9062900 raw words (2367869 effective words) took 36.6s, 64658 effective words/s', 'datetime': '2024-09-23T19:51:21.471094', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    train_documents,\n",
    "    total_examples=model.corpus_count,\n",
    "    epochs=70\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste de 'sanidade', calculando similaridade de documentos em relação ao conjunto todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ranks = []\n",
    "train_features = []\n",
    "\n",
    "for _, record in X_train.iterrows():\n",
    "    inferred_vector = model.infer_vector(record['review_comment_title_and_message'], epochs=0)\n",
    "    train_features.append(inferred_vector)\n",
    "\n",
    "    sims = model.dv.most_similar([inferred_vector])\n",
    "    rank = [docid for docid, _ in sims].index(record['review_tag'])\n",
    "    \n",
    "    train_ranks.append(rank)\n",
    "\n",
    "X_train['document_embeddings'] = train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 13378, 1: 2189, 2: 945})"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(train_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13514 de 16512 avaliações (81,05 %) são similares a elas mesmas, considerando o segundo vetor mais similar (2200) são 94,37 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ranks = []\n",
    "test_features = []\n",
    "\n",
    "for _, record in X_test.iterrows():\n",
    "    inferred_vector = model.infer_vector(record['review_comment_title_and_message'], epochs=0)\n",
    "    test_features.append(inferred_vector)\n",
    "\n",
    "    sims = model.dv.most_similar([inferred_vector])\n",
    "    rank = [docid for docid, _ in sims].index(record['review_tag'])\n",
    "    test_ranks.append(rank)\n",
    "\n",
    "X_test['document_embeddings'] = test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3057, 1: 642, 2: 430})"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(test_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3068 de 4129 avaliações (74,3 %) são similares a elas mesmas, considerando o segundo vetor mais similar (644) são 89,9 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Document (23) | tag (negative): «vendeu um produto entregou outro de qualidade infinitamente inferior»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec<dm/c,d400,n5,w7,mc3,s1e-05,t8>:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('negative', 0.9044221639633179),\n",
       " ('neutral', -0.4551694691181183),\n",
       " ('positive', -0.599165141582489)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_id = 23\n",
    "\n",
    "inferred_vector = model.infer_vector(train_documents[doc_id].words, epochs=0)\n",
    "sims = model.dv.most_similar([inferred_vector])\n",
    "\n",
    "print('Train Document ({}) | tag ({}): «{}»\\n'.format(doc_id, train_documents[doc_id].tags[0], ' '.join(train_documents[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "sims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando o modelo com o conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (1928) | tag (positive): «recomendo nao vao se arrepender»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec<dm/c,d400,n5,w7,mc3,s1e-05,t8>:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('negative', 0.8566605448722839),\n",
       " ('neutral', 0.25025463104248047),\n",
       " ('positive', -0.8897149562835693)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_id = random.randint(0, len(test_documents) - 1)\n",
    "\n",
    "inferred_vector = model.infer_vector(test_documents[doc_id].words, epochs=0)\n",
    "sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "\n",
    "print('Test Document ({}) | tag ({}): «{}»\\n'.format(doc_id, test_documents[doc_id].tags[0], ' '.join(test_documents[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "sims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Busca semântica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('negative', 0.8972170352935791),\n",
       " ('neutral', -0.09920229017734528),\n",
       " ('positive', -0.8382478356361389)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_query = 'nao gostei do produto horrivel'\n",
    "\n",
    "inferred_vector = model.infer_vector(semantic_query.split(' '), epochs=0)\n",
    "model.dv.most_similar([inferred_vector])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando modelo Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 19:54:07,854 : INFO : Doc2Vec lifecycle event {'fname_or_handle': '../model/doc2vec_olist_reviews_model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2024-09-23T19:54:07.854922', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'saving'}\n",
      "2024-09-23 19:54:07,858 : INFO : storing np array 'syn1neg' to ../model/doc2vec_olist_reviews_model.syn1neg.npy\n",
      "2024-09-23 19:54:08,010 : INFO : not storing attribute cum_table\n",
      "2024-09-23 19:54:08,017 : INFO : saved ../model/doc2vec_olist_reviews_model\n"
     ]
    }
   ],
   "source": [
    "model.save('../model/doc2vec_olist_reviews_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerando dataset com features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_doc2vec = X_train.loc[:, ['document_embeddings', 'review_sentiment']]\n",
    "X_test_doc2vec = X_test.loc[:, ['document_embeddings', 'review_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_doc2vec_embeddings = pd.DataFrame(\n",
    "    X_train_doc2vec['document_embeddings'].to_list(),\n",
    "    index=X_train_doc2vec.index\n",
    ")\n",
    "\n",
    "X_train_doc2vec_embeddings['review_sentiment'] = X_train_doc2vec['review_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_doc2vec_embeddings = pd.DataFrame(\n",
    "    X_test_doc2vec['document_embeddings'].to_list(),\n",
    "    index=X_test_doc2vec.index\n",
    ")\n",
    "\n",
    "X_test_doc2vec_embeddings['review_sentiment'] = X_test_doc2vec['review_sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando dataset com features na camada de delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\io\\parquet.py:190: UserWarning: The DataFrame has column names of mixed type. They will be converted to strings and not roundtrip correctly.\n",
      "  table = self.api.Table.from_pandas(df, **from_pandas_kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train_doc2vec_embeddings.to_parquet(\n",
    "    path='../dataset/featured/frzd_olist_document_embeddings_train.parquet.snappy',\n",
    "    engine='pyarrow',\n",
    "    compression='snappy',\n",
    "    index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_doc2vec_embeddings.to_parquet(\n",
    "    path='../dataset/featured/frzd_olist_document_embeddings_test.parquet.snappy',\n",
    "    engine='pyarrow',\n",
    "    compression='snappy',\n",
    "    index=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eEDB-002-2024-3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
