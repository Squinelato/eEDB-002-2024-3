{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import collections\n",
    "import logging\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurando nível de logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lendo arquivos de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frzd_olist_order_reviews = pd.read_parquet('../dataset/delivery/dlzd_olist_order_reviews.parquet.snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_comment_title_and_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
       "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>[parabens, lojas, lannister, adorei, comprar, ...</td>\n",
       "      <td>[parabens, lojas, lannister, adorei, comprar, ...</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>2018-03-02 10:26:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8670d52e15e00043ae7de4c01cc2fe06</td>\n",
       "      <td>b9bf720beb4ab3728760088589c62129</td>\n",
       "      <td>4</td>\n",
       "      <td>[recomendo]</td>\n",
       "      <td>[aparelho, eficiente, no, site, marca, do, apa...</td>\n",
       "      <td>[recomendo, aparelho, eficiente, no, site, mar...</td>\n",
       "      <td>2018-05-22</td>\n",
       "      <td>2018-05-23 16:45:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4b49719c8a200003f700d3d986ea1a19</td>\n",
       "      <td>9d6f15f95d01e79bd1349cc208361f09</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[mas, um, pouco, travando, pelo, valor, ta, boa]</td>\n",
       "      <td>[mas, um, pouco, travando, pelo, valor, ta, boa]</td>\n",
       "      <td>2018-02-16</td>\n",
       "      <td>2018-02-20 10:52:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d21bbc789670eab777d27372ab9094cc</td>\n",
       "      <td>4fc44d78867142c627497b60a7e0228a</td>\n",
       "      <td>5</td>\n",
       "      <td>[otimo]</td>\n",
       "      <td>[loja, nota]</td>\n",
       "      <td>[otimo, loja, nota]</td>\n",
       "      <td>2018-07-10</td>\n",
       "      <td>2018-07-11 14:10:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e0190b9db53b689b285d3f3916f8441</td>\n",
       "      <td>79832b7cb59ac6f887088ffd686e1d5e</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>[obrigado, pela, atencao, amim, dispensada]</td>\n",
       "      <td>[obrigado, pela, atencao, amim, dispensada]</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>2017-12-09 22:58:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id                          order_id  \\\n",
       "0  f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
       "1  8670d52e15e00043ae7de4c01cc2fe06  b9bf720beb4ab3728760088589c62129   \n",
       "2  4b49719c8a200003f700d3d986ea1a19  9d6f15f95d01e79bd1349cc208361f09   \n",
       "3  d21bbc789670eab777d27372ab9094cc  4fc44d78867142c627497b60a7e0228a   \n",
       "4  0e0190b9db53b689b285d3f3916f8441  79832b7cb59ac6f887088ffd686e1d5e   \n",
       "\n",
       "   review_score review_comment_title  \\\n",
       "0             5                   []   \n",
       "1             4          [recomendo]   \n",
       "2             4                   []   \n",
       "3             5              [otimo]   \n",
       "4             5                   []   \n",
       "\n",
       "                              review_comment_message  \\\n",
       "0  [parabens, lojas, lannister, adorei, comprar, ...   \n",
       "1  [aparelho, eficiente, no, site, marca, do, apa...   \n",
       "2   [mas, um, pouco, travando, pelo, valor, ta, boa]   \n",
       "3                                       [loja, nota]   \n",
       "4        [obrigado, pela, atencao, amim, dispensada]   \n",
       "\n",
       "                    review_comment_title_and_message review_creation_date  \\\n",
       "0  [parabens, lojas, lannister, adorei, comprar, ...           2018-03-01   \n",
       "1  [recomendo, aparelho, eficiente, no, site, mar...           2018-05-22   \n",
       "2   [mas, um, pouco, travando, pelo, valor, ta, boa]           2018-02-16   \n",
       "3                                [otimo, loja, nota]           2018-07-10   \n",
       "4        [obrigado, pela, atencao, amim, dispensada]           2017-12-01   \n",
       "\n",
       "  review_answer_timestamp  \n",
       "0     2018-03-02 10:26:53  \n",
       "1     2018-05-23 16:45:47  \n",
       "2     2018-02-20 10:52:22  \n",
       "3     2018-07-11 14:10:25  \n",
       "4     2017-12-09 22:58:58  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frzd_olist_order_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividindo entre conjunto de treino e teste de forma stratificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = frzd_olist_order_reviews.loc[:, ['review_comment_title_and_message', 'review_score']]\n",
    "y = frzd_olist_order_reviews.loc[:, ['review_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=51\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando tag para armazenar marcar cada documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents = []\n",
    "\n",
    "for index, data in X_train.iterrows():\n",
    "    train_documents.append(TaggedDocument(data['review_comment_title_and_message'].tolist(), [str(data['review_score']) + '_star_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_documents = []\n",
    "\n",
    "for index, data in X_test.iterrows():\n",
    "    test_documents.append(TaggedDocument(data['review_comment_title_and_message'].tolist(), [str(data['review_score']) + '_star_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo modelo Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 10:47:17,117 : INFO : using concatenative 5200-dimensional layer1\n",
      "2024-09-21 10:47:17,121 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/c,d400,n20,w6,mc4,s1e-05,t8>', 'datetime': '2024-09-21T10:47:17.121579', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(\n",
    "    vector_size=400, # tamanho do vetor de embedding\n",
    "    min_count=4, # quantidade mínima de repetições palavras para entrarem no treinamento \n",
    "    sample=10**-5, # frequência teórica para ponderar palavras muito frequêntes\n",
    "    window=6,\n",
    "    shrink_windows=True,\n",
    "    hs=0, # utilizando amostragem negativa para acelarar o treinamento\n",
    "    negative=20, # determina que 20 palavras aleatórias serão utilizadas para treinar a palavra predita\n",
    "    dm=1, # usando modelo PV-DM\n",
    "    dm_concat=1, # concatenando vetor de parágrafo com de palavras\n",
    "    dbow_words=1, # treinando também vetor de palavras word2vec\n",
    "    workers=8, # numero de cores utilizados no paralelismo\n",
    "    seed=51, # fixando a aleatoriada para deixar o modelo reprodutível\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 10:47:18,725 : INFO : collecting all words and their counts\n",
      "2024-09-21 10:47:18,728 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2024-09-21 10:47:18,780 : INFO : PROGRESS: at example #10000, processed 83266 words (1659515 words/s), 6819 word types, 5 tags\n",
      "2024-09-21 10:47:18,806 : INFO : collected 9668 word types and 5 unique tags from a corpus of 18721 examples and 157562 words\n",
      "2024-09-21 10:47:18,807 : INFO : Creating a fresh vocabulary\n",
      "2024-09-21 10:47:18,821 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=4 retains 2657 unique words (27.48% of original 9668, drops 7011)', 'datetime': '2024-09-21T10:47:18.821824', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-09-21 10:47:18,822 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=4 leaves 147935 word corpus (93.89% of original 157562, drops 9627)', 'datetime': '2024-09-21T10:47:18.822822', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-09-21 10:47:18,848 : INFO : deleting the raw counts dictionary of 9668 items\n",
      "2024-09-21 10:47:18,850 : INFO : sample=1e-05 downsamples 2657 most-common words\n",
      "2024-09-21 10:47:18,850 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 19861.8849965113 word corpus (13.4%% of prior 147935)', 'datetime': '2024-09-21T10:47:18.850823', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-09-21 10:47:18,879 : INFO : estimated required memory for 2657 words and 400 dimensions: 60854300 bytes\n",
      "2024-09-21 10:47:18,880 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(train_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 10:47:19,665 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 8 workers on 2658 vocabulary and 5200 features, using sg=0 hs=0 sample=1e-05 negative=20 window=6 shrink_windows=True', 'datetime': '2024-09-21T10:47:19.665967', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'train'}\n",
      "2024-09-21 10:47:20,819 : INFO : EPOCH 0 - PROGRESS: at 57.68% examples, 19799 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-21 10:47:20,870 : INFO : EPOCH 0: training on 157562 raw words (38640 effective words) took 1.2s, 32960 effective words/s\n",
      "2024-09-21 10:47:21,812 : INFO : EPOCH 1: training on 157562 raw words (38565 effective words) took 0.9s, 42231 effective words/s\n",
      "2024-09-21 10:47:22,709 : INFO : EPOCH 2: training on 157562 raw words (38469 effective words) took 0.9s, 44032 effective words/s\n",
      "2024-09-21 10:47:23,591 : INFO : EPOCH 3: training on 157562 raw words (38390 effective words) took 0.9s, 44629 effective words/s\n",
      "2024-09-21 10:47:24,471 : INFO : EPOCH 4: training on 157562 raw words (38557 effective words) took 0.9s, 44573 effective words/s\n",
      "2024-09-21 10:47:25,379 : INFO : EPOCH 5: training on 157562 raw words (38430 effective words) took 0.9s, 43753 effective words/s\n",
      "2024-09-21 10:47:26,213 : INFO : EPOCH 6: training on 157562 raw words (38628 effective words) took 0.8s, 47519 effective words/s\n",
      "2024-09-21 10:47:27,032 : INFO : EPOCH 7: training on 157562 raw words (38505 effective words) took 0.8s, 47689 effective words/s\n",
      "2024-09-21 10:47:27,832 : INFO : EPOCH 8: training on 157562 raw words (38421 effective words) took 0.8s, 49510 effective words/s\n",
      "2024-09-21 10:47:28,729 : INFO : EPOCH 9: training on 157562 raw words (38759 effective words) took 0.9s, 44206 effective words/s\n",
      "2024-09-21 10:47:29,586 : INFO : EPOCH 10: training on 157562 raw words (38681 effective words) took 0.8s, 45862 effective words/s\n",
      "2024-09-21 10:47:30,478 : INFO : EPOCH 11: training on 157562 raw words (38565 effective words) took 0.9s, 44080 effective words/s\n",
      "2024-09-21 10:47:31,349 : INFO : EPOCH 12: training on 157562 raw words (38676 effective words) took 0.8s, 45822 effective words/s\n",
      "2024-09-21 10:47:32,222 : INFO : EPOCH 13: training on 157562 raw words (38735 effective words) took 0.9s, 45510 effective words/s\n",
      "2024-09-21 10:47:33,071 : INFO : EPOCH 14: training on 157562 raw words (38532 effective words) took 0.8s, 46724 effective words/s\n",
      "2024-09-21 10:47:33,929 : INFO : EPOCH 15: training on 157562 raw words (38615 effective words) took 0.8s, 46039 effective words/s\n",
      "2024-09-21 10:47:34,792 : INFO : EPOCH 16: training on 157562 raw words (38536 effective words) took 0.8s, 45630 effective words/s\n",
      "2024-09-21 10:47:35,651 : INFO : EPOCH 17: training on 157562 raw words (38727 effective words) took 0.8s, 46302 effective words/s\n",
      "2024-09-21 10:47:36,502 : INFO : EPOCH 18: training on 157562 raw words (38693 effective words) took 0.8s, 46976 effective words/s\n",
      "2024-09-21 10:47:37,359 : INFO : EPOCH 19: training on 157562 raw words (38608 effective words) took 0.8s, 46350 effective words/s\n",
      "2024-09-21 10:47:37,360 : INFO : Doc2Vec lifecycle event {'msg': 'training on 3151240 raw words (771732 effective words) took 17.7s, 43631 effective words/s', 'datetime': '2024-09-21T10:47:37.360105', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    train_documents,\n",
    "    total_examples=model.corpus_count,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste de 'sanidade', calculando similaridade de documentos em relação ao conjunto todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ranks = []\n",
    "\n",
    "for document in train_documents:\n",
    "    inferred_vector = model.infer_vector(document.words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "    rank = [docid for docid, sim in sims].index(document.tags[0])\n",
    "    train_ranks.append(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 11462, 1: 3440, 2: 1638, 3: 1147, 4: 1034})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(train_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x de 18721 avaliações (x %) são similares a elas mesmas, o que é um bom sinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ranks = []\n",
    "\n",
    "for document in test_documents:\n",
    "    inferred_vector = model.infer_vector(document.words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "    rank = [docid for docid, sim in sims].index(document.tags[0])\n",
    "    test_ranks.append(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 2505, 1: 793, 2: 570, 3: 432, 4: 381})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(test_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x de 4681 avaliações (x %) são similares a elas mesmas, o que é um bom sinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (55) | tag (4_star_score): «muito boa»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec<dm/c,d300,n20,w5,mc2,s1e-06,t8>:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('3_star_score', 0.08512957394123077),\n",
       " ('1_star_score', 0.0543084517121315),\n",
       " ('2_star_score', 0.020415732637047768),\n",
       " ('5_star_score', -0.06042415648698807),\n",
       " ('4_star_score', -0.09239460527896881)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_id = 55\n",
    "\n",
    "inferred_vector = model.infer_vector(train_documents[doc_id].words)\n",
    "sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "\n",
    "print('Document ({}) | tag ({}): «{}»\\n'.format(doc_id, train_documents[doc_id].tags[0], ' '.join(train_documents[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "# for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "#     # print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_documents[sims[index][0]].words)))\n",
    "#     print()\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST (5807, -0.22642099857330322): «suporta ate»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "semantic_query = 'estou com problemas com meu numero da claro'\n",
    "\n",
    "inferred_vector = model.infer_vector(semantic_query.split(' '))\n",
    "sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "\n",
    "print(u'%s %s: «%s»\\n' % ('MOST', sims[index], ' '.join(train_documents[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando o modelo com o conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (3221): «otimo»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec<dm/c,d300,n20,w5,mc5,s1e-05,t8>:\n",
      "\n",
      "MOST (8283, 0.22291600704193115): «muito rui eles nao ciporta com criente»\n",
      "\n",
      "MEDIAN (12816, 0.0006949880626052618): «nota»\n",
      "\n",
      "LEAST (13287, -0.24041034281253815): «toner ja esta instalado funcionando perfeitamente»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Escolhendo aleatoriamente um documento do conjunto de teste\n",
    "doc_id = random.randint(0, len(test_documents) - 1)\n",
    "inferred_vector = model.infer_vector(test_documents[doc_id])\n",
    "sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "\n",
    "# Comparando este documento com o conjunto de treinamento\n",
    "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(test_documents[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_documents[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando modelo Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 19:02:23,668 : INFO : Doc2Vec lifecycle event {'fname_or_handle': '../model/doc2vec_telecom_pandemic_claims', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2024-09-19T19:02:23.667075', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'saving'}\n",
      "2024-09-19 19:02:23,672 : INFO : storing np array 'syn1neg' to ../model/doc2vec_telecom_pandemic_claims.syn1neg.npy\n",
      "2024-09-19 19:02:23,999 : INFO : not storing attribute cum_table\n",
      "2024-09-19 19:02:24,126 : INFO : saved ../model/doc2vec_telecom_pandemic_claims\n"
     ]
    }
   ],
   "source": [
    "model.save('../model/doc2vec_telecom_pandemic_claims')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eEDB-002-2024-3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
