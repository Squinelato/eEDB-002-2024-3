{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import collections\n",
    "import logging\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurando n√≠vel de logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lendo arquivos de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "frzd_olist_order_reviews = pd.read_parquet('../dataset/delivery/dlzd_olist_order_reviews.parquet.snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_comment_title_and_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
       "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>[parabens, lojas, lannister, adorei, comprar, ...</td>\n",
       "      <td>[parabens, lojas, lannister, adorei, comprar, ...</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>2018-03-02 10:26:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8670d52e15e00043ae7de4c01cc2fe06</td>\n",
       "      <td>b9bf720beb4ab3728760088589c62129</td>\n",
       "      <td>4</td>\n",
       "      <td>[recomendo]</td>\n",
       "      <td>[aparelho, eficiente, no, site, marca, do, apa...</td>\n",
       "      <td>[recomendo, aparelho, eficiente, no, site, mar...</td>\n",
       "      <td>2018-05-22</td>\n",
       "      <td>2018-05-23 16:45:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4b49719c8a200003f700d3d986ea1a19</td>\n",
       "      <td>9d6f15f95d01e79bd1349cc208361f09</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[mas, um, pouco, travando, pelo, valor, ta, boa]</td>\n",
       "      <td>[mas, um, pouco, travando, pelo, valor, ta, boa]</td>\n",
       "      <td>2018-02-16</td>\n",
       "      <td>2018-02-20 10:52:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d21bbc789670eab777d27372ab9094cc</td>\n",
       "      <td>4fc44d78867142c627497b60a7e0228a</td>\n",
       "      <td>5</td>\n",
       "      <td>[otimo]</td>\n",
       "      <td>[loja, nota]</td>\n",
       "      <td>[otimo, loja, nota]</td>\n",
       "      <td>2018-07-10</td>\n",
       "      <td>2018-07-11 14:10:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e0190b9db53b689b285d3f3916f8441</td>\n",
       "      <td>79832b7cb59ac6f887088ffd686e1d5e</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>[obrigado, pela, atencao, amim, dispensada]</td>\n",
       "      <td>[obrigado, pela, atencao, amim, dispensada]</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>2017-12-09 22:58:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id                          order_id  \\\n",
       "0  f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
       "1  8670d52e15e00043ae7de4c01cc2fe06  b9bf720beb4ab3728760088589c62129   \n",
       "2  4b49719c8a200003f700d3d986ea1a19  9d6f15f95d01e79bd1349cc208361f09   \n",
       "3  d21bbc789670eab777d27372ab9094cc  4fc44d78867142c627497b60a7e0228a   \n",
       "4  0e0190b9db53b689b285d3f3916f8441  79832b7cb59ac6f887088ffd686e1d5e   \n",
       "\n",
       "   review_score review_comment_title  \\\n",
       "0             5                   []   \n",
       "1             4          [recomendo]   \n",
       "2             4                   []   \n",
       "3             5              [otimo]   \n",
       "4             5                   []   \n",
       "\n",
       "                              review_comment_message  \\\n",
       "0  [parabens, lojas, lannister, adorei, comprar, ...   \n",
       "1  [aparelho, eficiente, no, site, marca, do, apa...   \n",
       "2   [mas, um, pouco, travando, pelo, valor, ta, boa]   \n",
       "3                                       [loja, nota]   \n",
       "4        [obrigado, pela, atencao, amim, dispensada]   \n",
       "\n",
       "                    review_comment_title_and_message review_creation_date  \\\n",
       "0  [parabens, lojas, lannister, adorei, comprar, ...           2018-03-01   \n",
       "1  [recomendo, aparelho, eficiente, no, site, mar...           2018-05-22   \n",
       "2   [mas, um, pouco, travando, pelo, valor, ta, boa]           2018-02-16   \n",
       "3                                [otimo, loja, nota]           2018-07-10   \n",
       "4        [obrigado, pela, atencao, amim, dispensada]           2017-12-01   \n",
       "\n",
       "  review_answer_timestamp  \n",
       "0     2018-03-02 10:26:53  \n",
       "1     2018-05-23 16:45:47  \n",
       "2     2018-02-20 10:52:22  \n",
       "3     2018-07-11 14:10:25  \n",
       "4     2017-12-09 22:58:58  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frzd_olist_order_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividindo entre conjunto de treino e teste de forma stratificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = frzd_olist_order_reviews.loc[:, ['review_comment_title_and_message']]\n",
    "y = frzd_olist_order_reviews.loc[:, ['review_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=51\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_comment_title_and_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[parabens, lojas, lannister, adorei, comprar, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[recomendo, aparelho, eficiente, no, site, mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[mas, um, pouco, travando, pelo, valor, ta, boa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[otimo, loja, nota]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[obrigado, pela, atencao, amim, dispensada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23397</th>\n",
       "      <td>[aprovado]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23398</th>\n",
       "      <td>[muito, bom, produto, ficamos, muito, satisfei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23399</th>\n",
       "      <td>[otima, embalagem]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23400</th>\n",
       "      <td>[foto, enganosa, foto, muito, diferente, princ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23401</th>\n",
       "      <td>[produto, nao, foi, enviado, com, nf, nao, exi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23402 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        review_comment_title_and_message\n",
       "0      [parabens, lojas, lannister, adorei, comprar, ...\n",
       "1      [recomendo, aparelho, eficiente, no, site, mar...\n",
       "2       [mas, um, pouco, travando, pelo, valor, ta, boa]\n",
       "3                                    [otimo, loja, nota]\n",
       "4            [obrigado, pela, atencao, amim, dispensada]\n",
       "...                                                  ...\n",
       "23397                                         [aprovado]\n",
       "23398  [muito, bom, produto, ficamos, muito, satisfei...\n",
       "23399                                 [otima, embalagem]\n",
       "23400  [foto, enganosa, foto, muito, diferente, princ...\n",
       "23401  [produto, nao, foi, enviado, com, nf, nao, exi...\n",
       "\n",
       "[23402 rows x 1 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando tag para armazenar marcar cada documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents = []\n",
    "\n",
    "for ordered_index, (index, data) in enumerate(X_train.iterrows()):\n",
    "    train_documents.append(TaggedDocument(data['review_comment_title_and_message'].tolist(), [ordered_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_documents = []\n",
    "\n",
    "for index, data in X_test.iterrows():\n",
    "    test_documents.append(data['review_comment_title_and_message'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo modelo Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 21:03:39,614 : INFO : using concatenative 2800-dimensional layer1\n",
      "2024-09-20 21:03:39,618 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/c,d400,n20,hs,w3,mc5,s0.001,t8>', 'datetime': '2024-09-20T21:03:39.618330', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(\n",
    "    vector_size=400, # tamanho do vetor de embedding\n",
    "    min_count=5, # quantidade m√≠nima de repeti√ß√µes palavras para entrarem no treinamento \n",
    "    sample=10**-5, # frequ√™ncia te√≥rica para ponderar palavras muito frequ√™ntes\n",
    "    window=3,\n",
    "    hs=1, # utilizando amostragem negativa para acelarar o treinamento\n",
    "    negative=20, # determina que 20 palavras aleat√≥rias ser√£o utilizadas para treinar a palavra predita\n",
    "    dm=1, # usando modelo PV-DM\n",
    "    dm_concat=1, # concatenando vetor de par√°grafo com de palavras\n",
    "    dbow_words=1, # treinando tamb√©m vetor de palavras word2vec\n",
    "    workers=8, # numero de cores utilizados no paralelismo\n",
    "    seed=51, # fixando a aleatoriada para deixar o modelo reprodut√≠vel\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando vocabul√°rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 21:03:42,255 : INFO : collecting all words and their counts\n",
      "2024-09-20 21:03:42,259 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2024-09-20 21:03:42,359 : INFO : PROGRESS: at example #10000, processed 83266 words (870376 words/s), 6819 word types, 0 tags\n",
      "2024-09-20 21:03:42,433 : INFO : collected 9668 word types and 18721 unique tags from a corpus of 18721 examples and 157562 words\n",
      "2024-09-20 21:03:42,437 : INFO : Creating a fresh vocabulary\n",
      "2024-09-20 21:03:42,488 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 2246 unique words (23.23% of original 9668, drops 7422)', 'datetime': '2024-09-20T21:03:42.487745', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-09-20 21:03:42,491 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 146291 word corpus (92.85% of original 157562, drops 11271)', 'datetime': '2024-09-20T21:03:42.491732', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-09-20 21:03:42,548 : INFO : deleting the raw counts dictionary of 9668 items\n",
      "2024-09-20 21:03:42,551 : INFO : sample=0.001 downsamples 61 most-common words\n",
      "2024-09-20 21:03:42,554 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 103200.78714318854 word corpus (70.5%% of prior 146291)', 'datetime': '2024-09-20T21:03:42.554994', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-09-20 21:03:42,562 : INFO : constructing a huffman tree from 2247 words\n",
      "2024-09-20 21:03:42,809 : INFO : built huffman tree with maximum node depth 16\n",
      "2024-09-20 21:03:42,885 : INFO : estimated required memory for 2246 words and 400 dimensions: 89174000 bytes\n",
      "2024-09-20 21:03:42,889 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(train_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 21:03:50,695 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2024-09-20 21:03:50,699 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 8 workers on 2247 vocabulary and 2800 features, using sg=0 hs=1 sample=0.001 negative=20 window=3 shrink_windows=True', 'datetime': '2024-09-20T21:03:50.699493', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'train'}\n",
      "2024-09-20 21:03:51,732 : INFO : EPOCH 0 - PROGRESS: at 19.28% examples, 23087 words/s, in_qsize 13, out_qsize 0\n",
      "2024-09-20 21:03:52,742 : INFO : EPOCH 0 - PROGRESS: at 62.32% examples, 37520 words/s, in_qsize 6, out_qsize 1\n",
      "2024-09-20 21:03:52,761 : INFO : EPOCH 0: training on 157562 raw words (121784 effective words) took 2.0s, 59883 effective words/s\n",
      "2024-09-20 21:03:53,799 : INFO : EPOCH 1 - PROGRESS: at 25.00% examples, 30379 words/s, in_qsize 11, out_qsize 1\n",
      "2024-09-20 21:03:54,839 : INFO : EPOCH 1 - PROGRESS: at 62.17% examples, 36825 words/s, in_qsize 6, out_qsize 1\n",
      "2024-09-20 21:03:54,872 : INFO : EPOCH 1: training on 157562 raw words (121747 effective words) took 2.1s, 58394 effective words/s\n",
      "2024-09-20 21:03:55,890 : INFO : EPOCH 2 - PROGRESS: at 44.81% examples, 53991 words/s, in_qsize 9, out_qsize 0\n",
      "2024-09-20 21:03:56,818 : INFO : EPOCH 2: training on 157562 raw words (121872 effective words) took 1.9s, 63117 effective words/s\n",
      "2024-09-20 21:03:58,552 : INFO : EPOCH 3 - PROGRESS: at 56.18% examples, 39401 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:03:58,710 : INFO : EPOCH 3: training on 157562 raw words (121704 effective words) took 1.9s, 64747 effective words/s\n",
      "2024-09-20 21:04:00,434 : INFO : EPOCH 4 - PROGRESS: at 56.18% examples, 39917 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:00,592 : INFO : EPOCH 4: training on 157562 raw words (121916 effective words) took 1.9s, 65528 effective words/s\n",
      "2024-09-20 21:04:02,253 : INFO : EPOCH 5 - PROGRESS: at 56.18% examples, 41404 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:02,445 : INFO : EPOCH 5: training on 157562 raw words (121781 effective words) took 1.8s, 66537 effective words/s\n",
      "2024-09-20 21:04:03,467 : INFO : EPOCH 6 - PROGRESS: at 32.27% examples, 38771 words/s, in_qsize 10, out_qsize 1\n",
      "2024-09-20 21:04:04,402 : INFO : EPOCH 6: training on 157562 raw words (122046 effective words) took 1.9s, 63070 effective words/s\n",
      "2024-09-20 21:04:06,143 : INFO : EPOCH 7 - PROGRESS: at 56.18% examples, 39539 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:06,298 : INFO : EPOCH 7: training on 157562 raw words (121885 effective words) took 1.9s, 65073 effective words/s\n",
      "2024-09-20 21:04:07,320 : INFO : EPOCH 8 - PROGRESS: at 51.25% examples, 61440 words/s, in_qsize 8, out_qsize 0\n",
      "2024-09-20 21:04:08,162 : INFO : EPOCH 8: training on 157562 raw words (122055 effective words) took 1.9s, 65919 effective words/s\n",
      "2024-09-20 21:04:09,826 : INFO : EPOCH 9 - PROGRESS: at 56.18% examples, 41266 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:09,975 : INFO : EPOCH 9: training on 157562 raw words (122096 effective words) took 1.8s, 67839 effective words/s\n",
      "2024-09-20 21:04:11,650 : INFO : EPOCH 10 - PROGRESS: at 56.18% examples, 41035 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:11,833 : INFO : EPOCH 10: training on 157562 raw words (121832 effective words) took 1.8s, 66267 effective words/s\n",
      "2024-09-20 21:04:13,393 : INFO : EPOCH 11 - PROGRESS: at 56.18% examples, 44239 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:13,552 : INFO : EPOCH 11: training on 157562 raw words (121866 effective words) took 1.7s, 71986 effective words/s\n",
      "2024-09-20 21:04:15,098 : INFO : EPOCH 12 - PROGRESS: at 56.18% examples, 44452 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:15,239 : INFO : EPOCH 12: training on 157562 raw words (121824 effective words) took 1.7s, 72941 effective words/s\n",
      "2024-09-20 21:04:16,747 : INFO : EPOCH 13 - PROGRESS: at 56.18% examples, 45753 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:16,901 : INFO : EPOCH 13: training on 157562 raw words (121732 effective words) took 1.6s, 74406 effective words/s\n",
      "2024-09-20 21:04:18,402 : INFO : EPOCH 14 - PROGRESS: at 56.18% examples, 45863 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:18,539 : INFO : EPOCH 14: training on 157562 raw words (121874 effective words) took 1.6s, 75306 effective words/s\n",
      "2024-09-20 21:04:20,013 : INFO : EPOCH 15 - PROGRESS: at 56.18% examples, 46634 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:20,168 : INFO : EPOCH 15: training on 157562 raw words (122243 effective words) took 1.6s, 75653 effective words/s\n",
      "2024-09-20 21:04:21,621 : INFO : EPOCH 16 - PROGRESS: at 56.18% examples, 47445 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:21,773 : INFO : EPOCH 16: training on 157562 raw words (122088 effective words) took 1.6s, 76890 effective words/s\n",
      "2024-09-20 21:04:23,233 : INFO : EPOCH 17 - PROGRESS: at 56.18% examples, 47367 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:23,374 : INFO : EPOCH 17: training on 157562 raw words (122213 effective words) took 1.6s, 77435 effective words/s\n",
      "2024-09-20 21:04:24,982 : INFO : EPOCH 18 - PROGRESS: at 56.18% examples, 42745 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:25,124 : INFO : EPOCH 18: training on 157562 raw words (121907 effective words) took 1.7s, 70366 effective words/s\n",
      "2024-09-20 21:04:26,583 : INFO : EPOCH 19 - PROGRESS: at 56.18% examples, 47234 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:26,705 : INFO : EPOCH 19: training on 157562 raw words (122083 effective words) took 1.6s, 78167 effective words/s\n",
      "2024-09-20 21:04:28,123 : INFO : EPOCH 20 - PROGRESS: at 56.18% examples, 48774 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:28,254 : INFO : EPOCH 20: training on 157562 raw words (121950 effective words) took 1.5s, 79866 effective words/s\n",
      "2024-09-20 21:04:29,671 : INFO : EPOCH 21 - PROGRESS: at 56.18% examples, 48329 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:29,795 : INFO : EPOCH 21: training on 157562 raw words (121793 effective words) took 1.5s, 79611 effective words/s\n",
      "2024-09-20 21:04:31,199 : INFO : EPOCH 22 - PROGRESS: at 56.18% examples, 49312 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:31,334 : INFO : EPOCH 22: training on 157562 raw words (122172 effective words) took 1.5s, 80542 effective words/s\n",
      "2024-09-20 21:04:32,764 : INFO : EPOCH 23 - PROGRESS: at 56.18% examples, 48205 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:32,916 : INFO : EPOCH 23: training on 157562 raw words (121919 effective words) took 1.6s, 78082 effective words/s\n",
      "2024-09-20 21:04:34,366 : INFO : EPOCH 24 - PROGRESS: at 56.18% examples, 47404 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:34,480 : INFO : EPOCH 24: training on 157562 raw words (122177 effective words) took 1.6s, 78706 effective words/s\n",
      "2024-09-20 21:04:35,866 : INFO : EPOCH 25 - PROGRESS: at 56.18% examples, 49479 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:36,001 : INFO : EPOCH 25: training on 157562 raw words (122096 effective words) took 1.5s, 80885 effective words/s\n",
      "2024-09-20 21:04:37,380 : INFO : EPOCH 26 - PROGRESS: at 56.18% examples, 49912 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:37,517 : INFO : EPOCH 26: training on 157562 raw words (121995 effective words) took 1.5s, 81397 effective words/s\n",
      "2024-09-20 21:04:38,887 : INFO : EPOCH 27 - PROGRESS: at 56.18% examples, 50437 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:39,028 : INFO : EPOCH 27: training on 157562 raw words (121892 effective words) took 1.5s, 81813 effective words/s\n",
      "2024-09-20 21:04:40,408 : INFO : EPOCH 28 - PROGRESS: at 56.18% examples, 49860 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:40,535 : INFO : EPOCH 28: training on 157562 raw words (121760 effective words) took 1.5s, 81868 effective words/s\n",
      "2024-09-20 21:04:41,914 : INFO : EPOCH 29 - PROGRESS: at 56.18% examples, 49711 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:42,038 : INFO : EPOCH 29: training on 157562 raw words (121765 effective words) took 1.5s, 81691 effective words/s\n",
      "2024-09-20 21:04:43,426 : INFO : EPOCH 30 - PROGRESS: at 56.18% examples, 49789 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:43,539 : INFO : EPOCH 30: training on 157562 raw words (122045 effective words) took 1.5s, 82466 effective words/s\n",
      "2024-09-20 21:04:44,917 : INFO : EPOCH 31 - PROGRESS: at 56.18% examples, 49942 words/s, in_qsize 7, out_qsize 1\n",
      "2024-09-20 21:04:45,046 : INFO : EPOCH 31: training on 157562 raw words (121691 effective words) took 1.5s, 81992 effective words/s\n",
      "2024-09-20 21:04:45,047 : INFO : Doc2Vec lifecycle event {'msg': 'training on 5041984 raw words (3901803 effective words) took 54.3s, 71799 effective words/s', 'datetime': '2024-09-20T21:04:45.047029', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    train_documents,\n",
    "    total_examples=model.corpus_count,\n",
    "    epochs=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste de 'sanidade', calculando similaridade de documentos em rela√ß√£o ao conjunto todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "\n",
    "for doc_id in range(len(train_documents)):\n",
    "    inferred_vector = model.infer_vector(train_documents[doc_id].words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 12864,\n",
       "         1: 671,\n",
       "         2: 312,\n",
       "         3: 225,\n",
       "         4: 190,\n",
       "         5: 139,\n",
       "         6: 117,\n",
       "         7: 113,\n",
       "         8: 86,\n",
       "         9: 80,\n",
       "         10: 74,\n",
       "         14: 61,\n",
       "         11: 57,\n",
       "         15: 56,\n",
       "         12: 55,\n",
       "         17: 50,\n",
       "         18: 46,\n",
       "         24: 45,\n",
       "         23: 45,\n",
       "         13: 45,\n",
       "         19: 44,\n",
       "         20: 43,\n",
       "         21: 34,\n",
       "         16: 34,\n",
       "         29: 34,\n",
       "         31: 33,\n",
       "         26: 31,\n",
       "         35: 31,\n",
       "         22: 30,\n",
       "         25: 28,\n",
       "         27: 27,\n",
       "         36: 27,\n",
       "         30: 25,\n",
       "         34: 25,\n",
       "         37: 24,\n",
       "         28: 24,\n",
       "         44: 23,\n",
       "         46: 21,\n",
       "         54: 21,\n",
       "         88: 20,\n",
       "         33: 20,\n",
       "         45: 20,\n",
       "         41: 20,\n",
       "         48: 20,\n",
       "         32: 20,\n",
       "         39: 19,\n",
       "         53: 19,\n",
       "         79: 18,\n",
       "         75: 18,\n",
       "         113: 18,\n",
       "         69: 18,\n",
       "         60: 18,\n",
       "         42: 17,\n",
       "         55: 17,\n",
       "         57: 17,\n",
       "         77: 16,\n",
       "         50: 16,\n",
       "         40: 16,\n",
       "         81: 16,\n",
       "         130: 16,\n",
       "         64: 16,\n",
       "         59: 15,\n",
       "         82: 15,\n",
       "         47: 15,\n",
       "         38: 15,\n",
       "         61: 15,\n",
       "         49: 14,\n",
       "         43: 14,\n",
       "         68: 14,\n",
       "         73: 14,\n",
       "         58: 14,\n",
       "         51: 14,\n",
       "         62: 14,\n",
       "         56: 14,\n",
       "         94: 13,\n",
       "         78: 13,\n",
       "         74: 13,\n",
       "         103: 13,\n",
       "         52: 13,\n",
       "         65: 13,\n",
       "         95: 13,\n",
       "         104: 13,\n",
       "         85: 12,\n",
       "         72: 12,\n",
       "         101: 12,\n",
       "         102: 12,\n",
       "         107: 11,\n",
       "         67: 11,\n",
       "         70: 11,\n",
       "         92: 11,\n",
       "         83: 11,\n",
       "         84: 11,\n",
       "         76: 11,\n",
       "         80: 11,\n",
       "         157: 10,\n",
       "         141: 10,\n",
       "         96: 10,\n",
       "         105: 10,\n",
       "         211: 10,\n",
       "         294: 9,\n",
       "         100: 9,\n",
       "         123: 9,\n",
       "         128: 9,\n",
       "         161: 9,\n",
       "         106: 9,\n",
       "         71: 9,\n",
       "         145: 9,\n",
       "         124: 9,\n",
       "         167: 9,\n",
       "         306: 9,\n",
       "         99: 9,\n",
       "         168: 9,\n",
       "         117: 9,\n",
       "         63: 9,\n",
       "         97: 8,\n",
       "         112: 8,\n",
       "         91: 8,\n",
       "         116: 8,\n",
       "         192: 8,\n",
       "         175: 8,\n",
       "         89: 8,\n",
       "         133: 8,\n",
       "         232: 8,\n",
       "         184: 8,\n",
       "         90: 8,\n",
       "         148: 8,\n",
       "         283: 8,\n",
       "         196: 8,\n",
       "         218: 8,\n",
       "         153: 8,\n",
       "         98: 8,\n",
       "         191: 7,\n",
       "         177: 7,\n",
       "         93: 7,\n",
       "         190: 7,\n",
       "         135: 7,\n",
       "         249: 7,\n",
       "         305: 7,\n",
       "         289: 7,\n",
       "         203: 7,\n",
       "         119: 7,\n",
       "         115: 7,\n",
       "         275: 7,\n",
       "         247: 7,\n",
       "         86: 7,\n",
       "         125: 7,\n",
       "         297: 7,\n",
       "         172: 7,\n",
       "         393: 7,\n",
       "         268: 7,\n",
       "         120: 7,\n",
       "         139: 7,\n",
       "         383: 7,\n",
       "         333: 7,\n",
       "         186: 6,\n",
       "         197: 6,\n",
       "         87: 6,\n",
       "         252: 6,\n",
       "         334: 6,\n",
       "         228: 6,\n",
       "         225: 6,\n",
       "         111: 6,\n",
       "         154: 6,\n",
       "         156: 6,\n",
       "         222: 6,\n",
       "         234: 6,\n",
       "         158: 6,\n",
       "         308: 6,\n",
       "         176: 6,\n",
       "         325: 6,\n",
       "         261: 6,\n",
       "         138: 6,\n",
       "         348: 6,\n",
       "         231: 6,\n",
       "         303: 6,\n",
       "         166: 6,\n",
       "         220: 6,\n",
       "         241: 6,\n",
       "         318: 6,\n",
       "         281: 6,\n",
       "         478: 6,\n",
       "         216: 6,\n",
       "         109: 6,\n",
       "         351: 6,\n",
       "         204: 6,\n",
       "         142: 6,\n",
       "         131: 6,\n",
       "         127: 6,\n",
       "         143: 6,\n",
       "         144: 6,\n",
       "         151: 6,\n",
       "         364: 6,\n",
       "         233: 5,\n",
       "         341: 5,\n",
       "         288: 5,\n",
       "         240: 5,\n",
       "         274: 5,\n",
       "         171: 5,\n",
       "         278: 5,\n",
       "         389: 5,\n",
       "         129: 5,\n",
       "         284: 5,\n",
       "         66: 5,\n",
       "         271: 5,\n",
       "         314: 5,\n",
       "         338: 5,\n",
       "         110: 5,\n",
       "         277: 5,\n",
       "         361: 5,\n",
       "         215: 5,\n",
       "         442: 5,\n",
       "         264: 5,\n",
       "         355: 5,\n",
       "         227: 5,\n",
       "         371: 5,\n",
       "         330: 5,\n",
       "         299: 5,\n",
       "         339: 5,\n",
       "         217: 5,\n",
       "         150: 5,\n",
       "         219: 5,\n",
       "         147: 5,\n",
       "         169: 5,\n",
       "         239: 5,\n",
       "         179: 5,\n",
       "         108: 5,\n",
       "         514: 5,\n",
       "         265: 5,\n",
       "         200: 5,\n",
       "         304: 5,\n",
       "         163: 5,\n",
       "         193: 5,\n",
       "         121: 5,\n",
       "         159: 5,\n",
       "         340: 5,\n",
       "         183: 5,\n",
       "         276: 4,\n",
       "         214: 4,\n",
       "         160: 4,\n",
       "         471: 4,\n",
       "         136: 4,\n",
       "         188: 4,\n",
       "         194: 4,\n",
       "         173: 4,\n",
       "         342: 4,\n",
       "         251: 4,\n",
       "         296: 4,\n",
       "         126: 4,\n",
       "         331: 4,\n",
       "         406: 4,\n",
       "         480: 4,\n",
       "         343: 4,\n",
       "         417: 4,\n",
       "         114: 4,\n",
       "         182: 4,\n",
       "         279: 4,\n",
       "         287: 4,\n",
       "         285: 4,\n",
       "         358: 4,\n",
       "         317: 4,\n",
       "         248: 4,\n",
       "         162: 4,\n",
       "         245: 4,\n",
       "         256: 4,\n",
       "         230: 4,\n",
       "         260: 4,\n",
       "         337: 4,\n",
       "         400: 4,\n",
       "         118: 4,\n",
       "         356: 4,\n",
       "         322: 4,\n",
       "         487: 4,\n",
       "         174: 4,\n",
       "         207: 4,\n",
       "         402: 4,\n",
       "         152: 4,\n",
       "         415: 4,\n",
       "         459: 4,\n",
       "         189: 4,\n",
       "         270: 4,\n",
       "         210: 4,\n",
       "         255: 4,\n",
       "         198: 4,\n",
       "         390: 4,\n",
       "         347: 4,\n",
       "         324: 4,\n",
       "         229: 4,\n",
       "         403: 4,\n",
       "         262: 4,\n",
       "         350: 4,\n",
       "         273: 4,\n",
       "         226: 4,\n",
       "         180: 4,\n",
       "         242: 4,\n",
       "         479: 4,\n",
       "         223: 4,\n",
       "         301: 4,\n",
       "         373: 4,\n",
       "         398: 4,\n",
       "         360: 4,\n",
       "         164: 4,\n",
       "         205: 4,\n",
       "         212: 4,\n",
       "         470: 4,\n",
       "         257: 4,\n",
       "         312: 3,\n",
       "         332: 3,\n",
       "         473: 3,\n",
       "         155: 3,\n",
       "         307: 3,\n",
       "         258: 3,\n",
       "         438: 3,\n",
       "         132: 3,\n",
       "         425: 3,\n",
       "         328: 3,\n",
       "         517: 3,\n",
       "         552: 3,\n",
       "         469: 3,\n",
       "         178: 3,\n",
       "         122: 3,\n",
       "         451: 3,\n",
       "         269: 3,\n",
       "         468: 3,\n",
       "         536: 3,\n",
       "         345: 3,\n",
       "         449: 3,\n",
       "         199: 3,\n",
       "         543: 3,\n",
       "         411: 3,\n",
       "         408: 3,\n",
       "         291: 3,\n",
       "         195: 3,\n",
       "         263: 3,\n",
       "         441: 3,\n",
       "         448: 3,\n",
       "         235: 3,\n",
       "         309: 3,\n",
       "         293: 3,\n",
       "         254: 3,\n",
       "         237: 3,\n",
       "         445: 3,\n",
       "         243: 3,\n",
       "         146: 3,\n",
       "         140: 3,\n",
       "         346: 3,\n",
       "         253: 3,\n",
       "         302: 3,\n",
       "         313: 3,\n",
       "         521: 3,\n",
       "         310: 3,\n",
       "         354: 3,\n",
       "         532: 3,\n",
       "         311: 3,\n",
       "         367: 3,\n",
       "         500: 3,\n",
       "         506: 3,\n",
       "         221: 3,\n",
       "         368: 3,\n",
       "         290: 3,\n",
       "         321: 3,\n",
       "         326: 3,\n",
       "         238: 3,\n",
       "         134: 3,\n",
       "         423: 3,\n",
       "         344: 3,\n",
       "         369: 3,\n",
       "         244: 3,\n",
       "         213: 3,\n",
       "         504: 2,\n",
       "         515: 2,\n",
       "         928: 2,\n",
       "         621: 2,\n",
       "         399: 2,\n",
       "         236: 2,\n",
       "         551: 2,\n",
       "         481: 2,\n",
       "         259: 2,\n",
       "         575: 2,\n",
       "         410: 2,\n",
       "         374: 2,\n",
       "         533: 2,\n",
       "         467: 2,\n",
       "         336: 2,\n",
       "         370: 2,\n",
       "         474: 2,\n",
       "         315: 2,\n",
       "         202: 2,\n",
       "         419: 2,\n",
       "         454: 2,\n",
       "         391: 2,\n",
       "         300: 2,\n",
       "         272: 2,\n",
       "         485: 2,\n",
       "         8026: 2,\n",
       "         505: 2,\n",
       "         6694: 2,\n",
       "         386: 2,\n",
       "         565: 2,\n",
       "         394: 2,\n",
       "         657: 2,\n",
       "         528: 2,\n",
       "         292: 2,\n",
       "         424: 2,\n",
       "         282: 2,\n",
       "         414: 2,\n",
       "         497: 2,\n",
       "         387: 2,\n",
       "         353: 2,\n",
       "         250: 2,\n",
       "         5028: 2,\n",
       "         137: 2,\n",
       "         298: 2,\n",
       "         483: 2,\n",
       "         352: 2,\n",
       "         422: 2,\n",
       "         319: 2,\n",
       "         187: 2,\n",
       "         444: 2,\n",
       "         413: 2,\n",
       "         542: 2,\n",
       "         463: 2,\n",
       "         566: 2,\n",
       "         503: 2,\n",
       "         280: 2,\n",
       "         431: 2,\n",
       "         450: 2,\n",
       "         494: 2,\n",
       "         381: 2,\n",
       "         206: 2,\n",
       "         329: 2,\n",
       "         428: 2,\n",
       "         170: 2,\n",
       "         466: 2,\n",
       "         787: 2,\n",
       "         453: 2,\n",
       "         372: 2,\n",
       "         512: 2,\n",
       "         3590: 2,\n",
       "         520: 2,\n",
       "         165: 2,\n",
       "         359: 2,\n",
       "         461: 2,\n",
       "         295: 2,\n",
       "         181: 2,\n",
       "         14749: 2,\n",
       "         365: 2,\n",
       "         513: 2,\n",
       "         323: 2,\n",
       "         388: 2,\n",
       "         15504: 1,\n",
       "         484: 1,\n",
       "         10021: 1,\n",
       "         7063: 1,\n",
       "         14929: 1,\n",
       "         5430: 1,\n",
       "         6562: 1,\n",
       "         931: 1,\n",
       "         401: 1,\n",
       "         11899: 1,\n",
       "         16539: 1,\n",
       "         9498: 1,\n",
       "         482: 1,\n",
       "         14936: 1,\n",
       "         6169: 1,\n",
       "         14521: 1,\n",
       "         582: 1,\n",
       "         5175: 1,\n",
       "         4039: 1,\n",
       "         418: 1,\n",
       "         5611: 1,\n",
       "         1802: 1,\n",
       "         17257: 1,\n",
       "         5009: 1,\n",
       "         17954: 1,\n",
       "         1881: 1,\n",
       "         7082: 1,\n",
       "         13648: 1,\n",
       "         13789: 1,\n",
       "         4640: 1,\n",
       "         10230: 1,\n",
       "         670: 1,\n",
       "         607: 1,\n",
       "         14549: 1,\n",
       "         15601: 1,\n",
       "         548: 1,\n",
       "         875: 1,\n",
       "         18209: 1,\n",
       "         583: 1,\n",
       "         7710: 1,\n",
       "         553: 1,\n",
       "         8250: 1,\n",
       "         6732: 1,\n",
       "         2543: 1,\n",
       "         16104: 1,\n",
       "         18090: 1,\n",
       "         507: 1,\n",
       "         363: 1,\n",
       "         4581: 1,\n",
       "         10756: 1,\n",
       "         16086: 1,\n",
       "         11027: 1,\n",
       "         18349: 1,\n",
       "         10785: 1,\n",
       "         10852: 1,\n",
       "         6574: 1,\n",
       "         405: 1,\n",
       "         430: 1,\n",
       "         4626: 1,\n",
       "         9766: 1,\n",
       "         11630: 1,\n",
       "         7308: 1,\n",
       "         7108: 1,\n",
       "         7985: 1,\n",
       "         686: 1,\n",
       "         616: 1,\n",
       "         518: 1,\n",
       "         834: 1,\n",
       "         382: 1,\n",
       "         665: 1,\n",
       "         6911: 1,\n",
       "         12369: 1,\n",
       "         585: 1,\n",
       "         6380: 1,\n",
       "         6881: 1,\n",
       "         524: 1,\n",
       "         16534: 1,\n",
       "         15070: 1,\n",
       "         10899: 1,\n",
       "         5275: 1,\n",
       "         629: 1,\n",
       "         7932: 1,\n",
       "         15470: 1,\n",
       "         491: 1,\n",
       "         455: 1,\n",
       "         1657: 1,\n",
       "         8191: 1,\n",
       "         10330: 1,\n",
       "         10326: 1,\n",
       "         7178: 1,\n",
       "         17554: 1,\n",
       "         15832: 1,\n",
       "         7621: 1,\n",
       "         13281: 1,\n",
       "         15093: 1,\n",
       "         17017: 1,\n",
       "         18100: 1,\n",
       "         15450: 1,\n",
       "         17229: 1,\n",
       "         4833: 1,\n",
       "         17836: 1,\n",
       "         4257: 1,\n",
       "         5612: 1,\n",
       "         7085: 1,\n",
       "         540: 1,\n",
       "         14085: 1,\n",
       "         2555: 1,\n",
       "         7236: 1,\n",
       "         11988: 1,\n",
       "         13096: 1,\n",
       "         4145: 1,\n",
       "         17568: 1,\n",
       "         224: 1,\n",
       "         12650: 1,\n",
       "         436: 1,\n",
       "         384: 1,\n",
       "         2692: 1,\n",
       "         13399: 1,\n",
       "         11218: 1,\n",
       "         4496: 1,\n",
       "         7192: 1,\n",
       "         11059: 1,\n",
       "         4627: 1,\n",
       "         2267: 1,\n",
       "         12523: 1,\n",
       "         539: 1,\n",
       "         375: 1,\n",
       "         9893: 1,\n",
       "         11140: 1,\n",
       "         9032: 1,\n",
       "         10646: 1,\n",
       "         2369: 1,\n",
       "         2635: 1,\n",
       "         407: 1,\n",
       "         15620: 1,\n",
       "         18437: 1,\n",
       "         13817: 1,\n",
       "         2464: 1,\n",
       "         16036: 1,\n",
       "         2420: 1,\n",
       "         765: 1,\n",
       "         12845: 1,\n",
       "         14080: 1,\n",
       "         490: 1,\n",
       "         3262: 1,\n",
       "         11187: 1,\n",
       "         6893: 1,\n",
       "         9749: 1,\n",
       "         15237: 1,\n",
       "         12172: 1,\n",
       "         1815: 1,\n",
       "         395: 1,\n",
       "         9755: 1,\n",
       "         7279: 1,\n",
       "         12291: 1,\n",
       "         511: 1,\n",
       "         8402: 1,\n",
       "         409: 1,\n",
       "         267: 1,\n",
       "         12544: 1,\n",
       "         574: 1,\n",
       "         5101: 1,\n",
       "         824: 1,\n",
       "         4285: 1,\n",
       "         11629: 1,\n",
       "         17178: 1,\n",
       "         412: 1,\n",
       "         17181: 1,\n",
       "         1371: 1,\n",
       "         16231: 1,\n",
       "         209: 1,\n",
       "         416: 1,\n",
       "         437: 1,\n",
       "         6319: 1,\n",
       "         9502: 1,\n",
       "         15576: 1,\n",
       "         10019: 1,\n",
       "         8153: 1,\n",
       "         10389: 1,\n",
       "         5601: 1,\n",
       "         16976: 1,\n",
       "         527: 1,\n",
       "         758: 1,\n",
       "         376: 1,\n",
       "         8219: 1,\n",
       "         397: 1,\n",
       "         11286: 1,\n",
       "         2963: 1,\n",
       "         16995: 1,\n",
       "         18447: 1,\n",
       "         16041: 1,\n",
       "         15668: 1,\n",
       "         916: 1,\n",
       "         439: 1,\n",
       "         2788: 1,\n",
       "         208: 1,\n",
       "         4495: 1,\n",
       "         385: 1,\n",
       "         6101: 1,\n",
       "         11365: 1,\n",
       "         797: 1,\n",
       "         14616: 1,\n",
       "         545: 1,\n",
       "         492: 1,\n",
       "         5310: 1,\n",
       "         11668: 1,\n",
       "         327: 1,\n",
       "         646: 1,\n",
       "         519: 1,\n",
       "         13378: 1,\n",
       "         7874: 1,\n",
       "         16987: 1,\n",
       "         11712: 1,\n",
       "         4736: 1,\n",
       "         15336: 1,\n",
       "         17802: 1,\n",
       "         3595: 1,\n",
       "         11053: 1,\n",
       "         17297: 1,\n",
       "         3259: 1,\n",
       "         8080: 1,\n",
       "         432: 1,\n",
       "         9837: 1,\n",
       "         15495: 1,\n",
       "         7610: 1,\n",
       "         1514: 1,\n",
       "         851: 1,\n",
       "         590: 1,\n",
       "         18212: 1,\n",
       "         778: 1,\n",
       "         499: 1,\n",
       "         17457: 1,\n",
       "         18176: 1,\n",
       "         10845: 1,\n",
       "         1700: 1,\n",
       "         7271: 1,\n",
       "         4231: 1,\n",
       "         12156: 1,\n",
       "         16518: 1,\n",
       "         869: 1,\n",
       "         1654: 1,\n",
       "         9528: 1,\n",
       "         1719: 1,\n",
       "         3412: 1,\n",
       "         1821: 1,\n",
       "         10822: 1,\n",
       "         9229: 1,\n",
       "         9201: 1,\n",
       "         5859: 1,\n",
       "         6928: 1,\n",
       "         849: 1,\n",
       "         13494: 1,\n",
       "         14379: 1,\n",
       "         8968: 1,\n",
       "         14271: 1,\n",
       "         15606: 1,\n",
       "         2347: 1,\n",
       "         620: 1,\n",
       "         6768: 1,\n",
       "         1625: 1,\n",
       "         10460: 1,\n",
       "         562: 1,\n",
       "         435: 1,\n",
       "         3496: 1,\n",
       "         335: 1,\n",
       "         3304: 1,\n",
       "         392: 1,\n",
       "         12819: 1,\n",
       "         639: 1,\n",
       "         1225: 1,\n",
       "         493: 1,\n",
       "         914: 1,\n",
       "         5029: 1,\n",
       "         16613: 1,\n",
       "         1695: 1,\n",
       "         10510: 1,\n",
       "         6841: 1,\n",
       "         4074: 1,\n",
       "         5166: 1,\n",
       "         6726: 1,\n",
       "         1160: 1,\n",
       "         5289: 1,\n",
       "         535: 1,\n",
       "         10355: 1,\n",
       "         16163: 1,\n",
       "         17086: 1,\n",
       "         508: 1,\n",
       "         452: 1,\n",
       "         12967: 1,\n",
       "         12232: 1,\n",
       "         11042: 1,\n",
       "         10271: 1,\n",
       "         10524: 1,\n",
       "         4089: 1,\n",
       "         8900: 1,\n",
       "         567: 1,\n",
       "         286: 1,\n",
       "         8127: 1,\n",
       "         6771: 1,\n",
       "         2591: 1,\n",
       "         6178: 1,\n",
       "         556: 1,\n",
       "         501: 1,\n",
       "         429: 1,\n",
       "         10366: 1,\n",
       "         201: 1,\n",
       "         266: 1,\n",
       "         11982: 1,\n",
       "         13044: 1,\n",
       "         7896: 1,\n",
       "         2131: 1,\n",
       "         366: 1,\n",
       "         4489: 1,\n",
       "         1279: 1,\n",
       "         6756: 1,\n",
       "         3310: 1,\n",
       "         806: 1,\n",
       "         440: 1,\n",
       "         6742: 1,\n",
       "         6782: 1,\n",
       "         18608: 1,\n",
       "         4315: 1,\n",
       "         7546: 1,\n",
       "         11176: 1,\n",
       "         185: 1,\n",
       "         531: 1,\n",
       "         9834: 1,\n",
       "         7673: 1,\n",
       "         4436: 1,\n",
       "         17523: 1,\n",
       "         7217: 1,\n",
       "         404: 1,\n",
       "         7465: 1,\n",
       "         5427: 1,\n",
       "         11771: 1,\n",
       "         554: 1,\n",
       "         635: 1,\n",
       "         9249: 1,\n",
       "         12194: 1,\n",
       "         881: 1,\n",
       "         576: 1,\n",
       "         5652: 1,\n",
       "         4938: 1,\n",
       "         13154: 1,\n",
       "         1363: 1,\n",
       "         18674: 1,\n",
       "         770: 1,\n",
       "         8916: 1,\n",
       "         14548: 1,\n",
       "         3981: 1,\n",
       "         1080: 1,\n",
       "         16006: 1,\n",
       "         443: 1,\n",
       "         10896: 1,\n",
       "         464: 1,\n",
       "         1707: 1,\n",
       "         2872: 1,\n",
       "         1847: 1,\n",
       "         10910: 1,\n",
       "         652: 1,\n",
       "         16137: 1,\n",
       "         17713: 1,\n",
       "         954: 1,\n",
       "         6081: 1,\n",
       "         641: 1,\n",
       "         11841: 1,\n",
       "         18675: 1,\n",
       "         12601: 1,\n",
       "         15347: 1,\n",
       "         18164: 1,\n",
       "         17360: 1,\n",
       "         16858: 1,\n",
       "         762: 1,\n",
       "         8616: 1,\n",
       "         10967: 1,\n",
       "         953: 1,\n",
       "         1104: 1,\n",
       "         18499: 1,\n",
       "         6615: 1,\n",
       "         1105: 1,\n",
       "         15973: 1,\n",
       "         3101: 1,\n",
       "         10889: 1,\n",
       "         2705: 1,\n",
       "         9767: 1,\n",
       "         427: 1,\n",
       "         1070: 1,\n",
       "         14248: 1,\n",
       "         14857: 1,\n",
       "         653: 1,\n",
       "         2739: 1,\n",
       "         8306: 1,\n",
       "         11195: 1,\n",
       "         844: 1,\n",
       "         11689: 1,\n",
       "         656: 1,\n",
       "         5136: 1,\n",
       "         2225: 1,\n",
       "         149: 1,\n",
       "         9574: 1,\n",
       "         16813: 1,\n",
       "         2265: 1,\n",
       "         3056: 1,\n",
       "         1484: 1,\n",
       "         5889: 1,\n",
       "         14166: 1,\n",
       "         18601: 1,\n",
       "         555: 1,\n",
       "         10776: 1,\n",
       "         18515: 1,\n",
       "         5735: 1,\n",
       "         4418: 1,\n",
       "         362: 1,\n",
       "         10262: 1,\n",
       "         10117: 1,\n",
       "         3752: 1,\n",
       "         15002: 1,\n",
       "         7427: 1,\n",
       "         522: 1,\n",
       "         7945: 1,\n",
       "         11973: 1,\n",
       "         917: 1,\n",
       "         18692: 1,\n",
       "         909: 1,\n",
       "         15958: 1,\n",
       "         685: 1,\n",
       "         15393: 1,\n",
       "         13457: 1,\n",
       "         14522: 1,\n",
       "         12838: 1,\n",
       "         447: 1,\n",
       "         396: 1,\n",
       "         8861: 1,\n",
       "         10677: 1,\n",
       "         458: 1,\n",
       "         13742: 1,\n",
       "         433: 1,\n",
       "         4016: 1,\n",
       "         645: 1,\n",
       "         5896: 1,\n",
       "         619: 1,\n",
       "         7671: 1,\n",
       "         7289: 1,\n",
       "         7339: 1,\n",
       "         7238: 1,\n",
       "         4301: 1,\n",
       "         434: 1,\n",
       "         9117: 1,\n",
       "         1098: 1,\n",
       "         578: 1,\n",
       "         15458: 1,\n",
       "         643: 1})"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18248 de 22635 reclama√ß√µes (80,62 %) s√£o similares a elas mesmas, o que √© um bom sinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (50): ¬´veio no tempo certo direito achei bolsa pequena pequena demais mas gostei ta valendo¬ª\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec<dm/c,d400,n20,hs,w3,mc5,s0.001,t8>:\n",
      "\n",
      "MOST (50, 0.968439519405365): ¬´veio no tempo certo direito achei bolsa pequena pequena demais mas gostei ta valendo¬ª\n",
      "\n",
      "SECOND-MOST (761, 0.6666141152381897): ¬´comprei pela primeira vez pra nunca mais decepcionadx¬ª\n",
      "\n",
      "MEDIAN (2571, 0.013635230250656605): ¬´pedido cancelado unilateralmente pela lojas lannister sem dar satisfacao¬ª\n",
      "\n",
      "LEAST (17734, -0.6238632202148438): ¬´claro super confiavel esta de parabens¬ª\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_id = 50\n",
    "\n",
    "inferred_vector = model.infer_vector(train_documents[doc_id].words)\n",
    "sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "\n",
    "print('Document ({}): ¬´{}¬ª\\n'.format(doc_id, ' '.join(train_documents[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: ¬´%s¬ª\\n' % (label, sims[index], ' '.join(train_documents[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST (5807, -0.22642099857330322): ¬´suporta ate¬ª\n",
      "\n"
     ]
    }
   ],
   "source": [
    "semantic_query = 'estou com problemas com meu numero da claro'\n",
    "\n",
    "inferred_vector = model.infer_vector(semantic_query.split(' '))\n",
    "sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "\n",
    "print(u'%s %s: ¬´%s¬ª\\n' % ('MOST', sims[index], ' '.join(train_documents[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando o modelo com o conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (3221): ¬´otimo¬ª\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec<dm/c,d300,n20,w5,mc5,s1e-05,t8>:\n",
      "\n",
      "MOST (8283, 0.22291600704193115): ¬´muito rui eles nao ciporta com criente¬ª\n",
      "\n",
      "MEDIAN (12816, 0.0006949880626052618): ¬´nota¬ª\n",
      "\n",
      "LEAST (13287, -0.24041034281253815): ¬´toner ja esta instalado funcionando perfeitamente¬ª\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Escolhendo aleatoriamente um documento do conjunto de teste\n",
    "doc_id = random.randint(0, len(test_documents) - 1)\n",
    "inferred_vector = model.infer_vector(test_documents[doc_id])\n",
    "sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "\n",
    "# Comparando este documento com o conjunto de treinamento\n",
    "print('Test Document ({}): ¬´{}¬ª\\n'.format(doc_id, ' '.join(test_documents[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: ¬´%s¬ª\\n' % (label, sims[index], ' '.join(train_documents[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando modelo Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 19:02:23,668 : INFO : Doc2Vec lifecycle event {'fname_or_handle': '../model/doc2vec_telecom_pandemic_claims', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2024-09-19T19:02:23.667075', 'gensim': '4.3.3', 'python': '3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'saving'}\n",
      "2024-09-19 19:02:23,672 : INFO : storing np array 'syn1neg' to ../model/doc2vec_telecom_pandemic_claims.syn1neg.npy\n",
      "2024-09-19 19:02:23,999 : INFO : not storing attribute cum_table\n",
      "2024-09-19 19:02:24,126 : INFO : saved ../model/doc2vec_telecom_pandemic_claims\n"
     ]
    }
   ],
   "source": [
    "model.save('../model/doc2vec_telecom_pandemic_claims')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eEDB-002-2024-3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
